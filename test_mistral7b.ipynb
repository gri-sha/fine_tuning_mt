{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64bfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_checkpoint = \"./finetuning_mistral7b_v2/checkpoint-89\"\n",
    "cache_dir = os.path.expanduser(\"~/.cache/huggingface/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "peftconfig = PeftConfig.from_pretrained(model_checkpoint)\n",
    "\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    peftconfig.base_model_name_or_path, device_map=\"auto\", cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=False,  # always False for inference\n",
    ")\n",
    "\n",
    "new_model = PeftModel.from_pretrained(model_base, model_checkpoint)\n",
    "print(\"Peft model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs,\n",
    "                                 max_new_tokens=20,\n",
    "                                 min_new_tokens=1,\n",
    "                                 do_sample=False,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "  return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a63615",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"English: Images raced through her mind as her daydreams took over\\nFrench: \"\n",
    "response = generate_response(prompt, new_model)\n",
    "print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
